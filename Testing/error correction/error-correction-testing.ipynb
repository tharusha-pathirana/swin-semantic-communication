{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tharu\\AppData\\Local\\Temp\\ipykernel_10288\\569774741.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  indices = torch.load('indices.pt')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the tensor\n",
    "indices = torch.load('indices.pt')\n",
    "\n",
    "indices_np = indices.numpy()  # Convert PyTorch tensor to NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**uint 16 for k=512**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding 6 blocks of size 255 bytes each.\n",
      "Block 5 could not be decoded. Retaining noisy data.\n",
      "Decoded Indices (Best Effort):\n",
      "[  394   290   165   493    23   129   121   285   113   427   393    23\n",
      "    77   229   419   188    82   265   297   125   450   283   457   128\n",
      "   455   213   424   295   302   286    29   119   402   315   436   107\n",
      "   429   378   243    69   229   280   316   275    84   476   238   283\n",
      "   113    20   466   287   453   372    44   256   255   377    51   185\n",
      "   393   392   373   493    38   158     7    50   365   414    16   246\n",
      "   170   197   336   195   403   509   130   298   128   375   135   450\n",
      "   381   406   283    28    19   237   472   433   167   286   131   421\n",
      "   291    91   188   281   209   226   412   236    21   457   484   350\n",
      "   108   263   179    64   101    87   374    35   388   480   135    13\n",
      "   329   271    13   116   132   172   330   188   102   119   387   240\n",
      "   466   212   415   501   253   480    21   250   149   331   210   423\n",
      "   253   466   388   113    16   185   193   414   224   437   247    14\n",
      "     7   432   458    37   284   227   260   154    12   473   429   324\n",
      "   206    84   135   142   364   501   339   231    26   337    87   134\n",
      "    49    50   363   220   165    30   486    35   215   435   242   490\n",
      "   260    63    47    95   151   237   412   176   281   404   345   254\n",
      "   308     7   244   349   460    22   341   285     7   182   120   143\n",
      "    27   440   134   360   276    66   156    23   376 51197     1   394\n",
      "   438   207   416   148   444    62   373   301   365   116   106   303\n",
      "    79   298   381   491   444   190   140    96   157   292   390   312\n",
      "   189    80    11   508   442   373   344   500   224    25   189    23\n",
      "   430   348   331    99   213   435   503   150   233   234   105    74\n",
      "   266   481    19   355   486   450   360   311   314   384   400   380\n",
      "   348   416    89  1498    42   243   416   195   249   124   276   103\n",
      "    93   248   162   348   504   188   181   498   156   441   451   253\n",
      "   404   173   124  8516    40   441   423   145    56   168    83    67\n",
      "   390   231   132    98   348   457   225   394    51   260   375   276\n",
      "   339   177    55    91    92   152   192   205   193   403    89   241\n",
      " 33158   168   450   436    82   426   265   472   414   422   370   109\n",
      "    18   200    19   193   332    92   361   176   373   302   265   349\n",
      "   146   501   479     7   305   429   459   487    17   385     1   276\n",
      "   184   387   378   252   473   211    83   391   169   465   494   350\n",
      "   253   468   171    85   463   173   307   222     9    38   268   434\n",
      "   450    94   352   409   426    34   137   201   185   272    66   228\n",
      "   413    96   299   114   298    80    75   487    97   505   111   498\n",
      "   195   120   215   175    89   379   418   398   186   459   390   243\n",
      "   141    51    51   469   458   148   330   206   175   390   342   219\n",
      "   330     9   104   178   318   357     2   129   129   471   479   441\n",
      "   240   187   257   284   494   344   137   149   211   377   373   200\n",
      "   199   430   264    49   231   424   491   215   498   325   247    43\n",
      "   454    62   254   406    44   436   425   179   200    36   276   219]\n",
      "\n",
      "Original Indices:\n",
      "[394 290 165 493  23 129 121 285 113 427 393  23  77 229 419 188  82 265\n",
      " 297 125 450 283 457 128 455 213 424 295 302 286  29 119 402 315 436 107\n",
      " 429 378 243  69 229 280 316 275  84 476 238 283 113  20 466 287 453 372\n",
      "  44 256 255 377  51 185 393 392 373 493  38 158   7  50 365 414  16 246\n",
      " 170 197 336 195 403 509 130 298 128 375 135 450 381 406 283  28  19 237\n",
      " 472 433 167 286 131 421 291  91 188 281 209 226 412 236  21 457 484 350\n",
      " 108 263 179  64 101  87 374  35 388 480 135  13 329 271  13 116 132 172\n",
      " 330 188 102 119 387 240 466 212 415 501 125 480  21 250 149 331 210 423\n",
      " 253 466 388 113  16 185 193 414 224 437 247  14   7 432 458  37 284 227\n",
      " 260 154  12 473 429 324 206  84 135 142 364 501 339 164  26 337  87 134\n",
      "  49  50 363 220 165  30 486  35 215 435 242 490 260  63  47  95 151 237\n",
      " 412 176 281 405 345 254 308   7 244 349 460  22 341 285   7 182 120 143\n",
      "  27 440 134 360 276  66 156  22 376 253   1 394 438 207 416 148 444  62\n",
      " 373 297 365 116 106 303  79 298 381 491 444 190 140  96 157 292 390 312\n",
      " 189  80  11 508 442 373 344 500 224  25 189  23 430 348 331  99 213 435\n",
      " 503 150 233 234 105  74 266 481  19 355 486 450 360 311 447 384 400 380\n",
      " 350 416  89 474  42 243 416 195 249 124 404 103  93 248 162 348 504 188\n",
      " 181 498 156 441 451 253 404 173 124 324  40 441 423 145  56 168  83  67\n",
      " 390 231 132  98 348 457 225 394  51 260 375 276 339 177  55  91  92 152\n",
      " 192 205 193 403  89 241 390 168 450 436 242 426 265 472 414 420 370 109\n",
      "  18 200  19 193 332  92 360 176 373 302 265 349 146 501 479   7 305 429\n",
      " 459 487  17 385   1 276 184 387 378 252 473 211  83 391 169 465 494 350\n",
      " 253 468 171  85 463 173 307 222   9  38 268 434 450  94 352 409 426  34\n",
      " 137 201 185 272  66 228 413  96 299 114 298  80  75 487  97 505 111 498\n",
      " 195 120 215 175  89 379 418 398 186 459 390 243 141  51  51 469 458 148\n",
      " 330 206 175 390 342 219 330   9 104 178 318 357   2 129 129 471 479 441\n",
      " 240 187 257 284 494 344 137 149 211 377 373 200 199 430 264  49 231 424\n",
      " 491 215 498 325 247  43 454  62 254 406  44 436 425 179 200  36 276 219]\n",
      "\n",
      "Original shape: (504,), Decoded shape: (504,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import reedsolo\n",
    "\n",
    "# Initialize RS codec\n",
    "r = 120  # Redundancy (4 symbols per block)\n",
    "n = 255  # Total symbols per block\n",
    "k = n - r  # Data symbols per block\n",
    "rs = reedsolo.RSCodec(r)\n",
    "\n",
    "# Simulated data\n",
    "original_size = 503 # Original data size\n",
    "indices = np.random.randint(0, 512, size=(original_size,), dtype=np.uint16)\n",
    "\n",
    "# Calculate padding\n",
    "padding_length = (k - (len(indices) % k)) % k\n",
    "padded_indices = np.pad(indices, (0, padding_length), mode='constant', constant_values=0)\n",
    "indices_bytes = padded_indices.tobytes()\n",
    "\n",
    "# Ensure that padded data length aligns with expected block size\n",
    "assert len(indices_bytes) % k == 0, \"Padded data size is not aligned with the block size.\"\n",
    "\n",
    "# Encode the data\n",
    "encoded_data = rs.encode(indices_bytes)\n",
    "\n",
    "# Simulate noise (add random bit errors based on error ratio)\n",
    "def add_noise_with_ratio(data, error_ratio):\n",
    "    \"\"\"\n",
    "    Add noise to the encoded data by flipping bits based on the error ratio.\n",
    "\n",
    "    Args:\n",
    "        data (bytes): Encoded data.\n",
    "        error_ratio (float): Fraction of bits to flip (e.g., 0.01 for 1% errors).\n",
    "\n",
    "    Returns:\n",
    "        bytes: Noisy data.\n",
    "    \"\"\"\n",
    "    noisy_data = bytearray(data)\n",
    "    total_bits = len(noisy_data) * 8  # Total number of bits in the data\n",
    "    num_errors = int(total_bits * error_ratio)  # Calculate the number of bits to flip\n",
    "\n",
    "    print(f\"Introducing {num_errors} errors out of {total_bits} total bits (ratio = {error_ratio}).\")\n",
    "\n",
    "    for _ in range(num_errors):\n",
    "        byte_index = np.random.randint(len(noisy_data))  # Random byte index\n",
    "        bit_index = np.random.randint(8)  # Random bit within the byte\n",
    "        noisy_data[byte_index] ^= (1 << bit_index)  # Flip the selected bit\n",
    "\n",
    "    return bytes(noisy_data)\n",
    "\n",
    "# Introduce noise with a given error ratio\n",
    "error_ratio = 0.025  # Flip 1% of the total bits\n",
    "noisy_data = add_noise_with_ratio(encoded_data, error_ratio)\n",
    "\n",
    "\n",
    "# Process data block by block\n",
    "def decode_blocks(encoded_data, block_size, data_size, redundancy):\n",
    "    decoded_result = bytearray()\n",
    "    num_blocks = len(encoded_data) // block_size\n",
    "\n",
    "    print(f\"Decoding {num_blocks} blocks of size {block_size} bytes each.\")\n",
    "\n",
    "    for i in range(num_blocks):\n",
    "        start = i * block_size\n",
    "        end = start + block_size\n",
    "        block = encoded_data[start:end]\n",
    "\n",
    "        try:\n",
    "            # Attempt to decode the block\n",
    "            decoded_block = rs.decode(block)\n",
    "            if isinstance(decoded_block, tuple):  # Handle tuple output\n",
    "                decoded_block = decoded_block[0]\n",
    "            decoded_result.extend(decoded_block[:data_size])  # Append only data symbols\n",
    "        except reedsolo.ReedSolomonError:\n",
    "            # Decoding failed, append raw noisy data for this block\n",
    "            print(f\"Block {i + 1} could not be decoded. Retaining noisy data.\")\n",
    "            decoded_result.extend(block[:data_size])  # Append raw data symbols (exclude redundancy)\n",
    "\n",
    "    return decoded_result\n",
    "\n",
    "# Decode the noisy data\n",
    "decoded_data = decode_blocks(noisy_data, block_size=n, data_size=k, redundancy=r)\n",
    "\n",
    "# Remove padding\n",
    "decoded_data = decoded_data[:original_size * 2]  # Trim to original data size (bytes)\n",
    "decoded_indices = np.frombuffer(decoded_data, dtype=np.uint16)\n",
    "\n",
    "# Validate shapes\n",
    "print(\"Decoded Indices (Best Effort):\")\n",
    "print(decoded_indices)\n",
    "\n",
    "print(\"\\nOriginal Indices:\")\n",
    "print(indices)\n",
    "\n",
    "print(f\"\\nOriginal shape: {indices.shape}, Decoded shape: {decoded_indices.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data saved to transmitted_data.bin\n",
      "Encoded data saved to transmitted_data.bin\n",
      "Introducing 6936 errors out of 173400 total bits (ratio = 0.04).\n",
      "Noisy data saved to noisy_data.bin\n",
      "Decoding 85 blocks of size 255 bytes each.\n",
      "Block 1 could not be decoded. Retaining noisy data.\n",
      "Block 2 could not be decoded. Retaining noisy data.\n",
      "Block 3 could not be decoded. Retaining noisy data.\n",
      "Block 4 could not be decoded. Retaining noisy data.\n",
      "Block 5 could not be decoded. Retaining noisy data.\n",
      "Block 6 could not be decoded. Retaining noisy data.\n",
      "Block 7 could not be decoded. Retaining noisy data.\n",
      "Block 8 could not be decoded. Retaining noisy data.\n",
      "Block 9 could not be decoded. Retaining noisy data.\n",
      "Block 10 could not be decoded. Retaining noisy data.\n",
      "Block 11 could not be decoded. Retaining noisy data.\n",
      "Block 12 could not be decoded. Retaining noisy data.\n",
      "Block 13 could not be decoded. Retaining noisy data.\n",
      "Block 14 could not be decoded. Retaining noisy data.\n",
      "Block 15 could not be decoded. Retaining noisy data.\n",
      "Block 16 could not be decoded. Retaining noisy data.\n",
      "Block 17 could not be decoded. Retaining noisy data.\n",
      "Block 18 could not be decoded. Retaining noisy data.\n",
      "Block 19 could not be decoded. Retaining noisy data.\n",
      "Block 20 could not be decoded. Retaining noisy data.\n",
      "Block 21 could not be decoded. Retaining noisy data.\n",
      "Block 22 could not be decoded. Retaining noisy data.\n",
      "Block 23 could not be decoded. Retaining noisy data.\n",
      "Block 24 could not be decoded. Retaining noisy data.\n",
      "Block 25 could not be decoded. Retaining noisy data.\n",
      "Block 26 could not be decoded. Retaining noisy data.\n",
      "Block 27 could not be decoded. Retaining noisy data.\n",
      "Block 28 could not be decoded. Retaining noisy data.\n",
      "Block 29 could not be decoded. Retaining noisy data.\n",
      "Block 30 could not be decoded. Retaining noisy data.\n",
      "Block 31 could not be decoded. Retaining noisy data.\n",
      "Block 32 could not be decoded. Retaining noisy data.\n",
      "Block 33 could not be decoded. Retaining noisy data.\n",
      "Block 34 could not be decoded. Retaining noisy data.\n",
      "Block 35 could not be decoded. Retaining noisy data.\n",
      "Block 36 could not be decoded. Retaining noisy data.\n",
      "Block 37 could not be decoded. Retaining noisy data.\n",
      "Block 38 could not be decoded. Retaining noisy data.\n",
      "Block 39 could not be decoded. Retaining noisy data.\n",
      "Block 40 could not be decoded. Retaining noisy data.\n",
      "Block 41 could not be decoded. Retaining noisy data.\n",
      "Block 42 could not be decoded. Retaining noisy data.\n",
      "Block 43 could not be decoded. Retaining noisy data.\n",
      "Block 44 could not be decoded. Retaining noisy data.\n",
      "Block 45 could not be decoded. Retaining noisy data.\n",
      "Block 46 could not be decoded. Retaining noisy data.\n",
      "Block 47 could not be decoded. Retaining noisy data.\n",
      "Block 48 could not be decoded. Retaining noisy data.\n",
      "Block 49 could not be decoded. Retaining noisy data.\n",
      "Block 50 could not be decoded. Retaining noisy data.\n",
      "Block 51 could not be decoded. Retaining noisy data.\n",
      "Block 52 could not be decoded. Retaining noisy data.\n",
      "Block 53 could not be decoded. Retaining noisy data.\n",
      "Block 54 could not be decoded. Retaining noisy data.\n",
      "Block 55 could not be decoded. Retaining noisy data.\n",
      "Block 56 could not be decoded. Retaining noisy data.\n",
      "Block 57 could not be decoded. Retaining noisy data.\n",
      "Block 58 could not be decoded. Retaining noisy data.\n",
      "Block 59 could not be decoded. Retaining noisy data.\n",
      "Block 60 could not be decoded. Retaining noisy data.\n",
      "Block 61 could not be decoded. Retaining noisy data.\n",
      "Block 62 could not be decoded. Retaining noisy data.\n",
      "Block 63 could not be decoded. Retaining noisy data.\n",
      "Block 64 could not be decoded. Retaining noisy data.\n",
      "Block 65 could not be decoded. Retaining noisy data.\n",
      "Block 66 could not be decoded. Retaining noisy data.\n",
      "Block 67 could not be decoded. Retaining noisy data.\n",
      "Block 68 could not be decoded. Retaining noisy data.\n",
      "Block 69 could not be decoded. Retaining noisy data.\n",
      "Block 70 could not be decoded. Retaining noisy data.\n",
      "Block 72 could not be decoded. Retaining noisy data.\n",
      "Block 74 could not be decoded. Retaining noisy data.\n",
      "Block 75 could not be decoded. Retaining noisy data.\n",
      "Block 76 could not be decoded. Retaining noisy data.\n",
      "Block 77 could not be decoded. Retaining noisy data.\n",
      "Block 78 could not be decoded. Retaining noisy data.\n",
      "Block 79 could not be decoded. Retaining noisy data.\n",
      "Block 80 could not be decoded. Retaining noisy data.\n",
      "Block 82 could not be decoded. Retaining noisy data.\n",
      "Block 83 could not be decoded. Retaining noisy data.\n",
      "Block 84 could not be decoded. Retaining noisy data.\n",
      "Block 85 could not be decoded. Retaining noisy data.\n",
      "Decoded indices saved to decoded_indices.bin\n",
      "\n",
      "Decoded Indices (Best Effort):\n",
      "[ 41  94 219 ... 207  74 245]\n",
      "\n",
      "Original Indices:\n",
      "[ 41  94 218 ... 207  72 245]\n",
      "\n",
      "Original shape: (12288,), Decoded shape: (12288,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import reedsolo\n",
    "\n",
    "# Initialize RS codec\n",
    "r = 110  # Redundancy (4 symbols per block)\n",
    "n = 255  # Total symbols per block\n",
    "k = n - r  # Data symbols per block\n",
    "rs = reedsolo.RSCodec(r)\n",
    "\n",
    "def transmitter(indices, output_file):\n",
    "    # Calculate padding\n",
    "    padding_length = (k - (len(indices) % k)) % k  # Padding to align data size to block size\n",
    "    padded_indices = np.pad(indices, (0, padding_length), mode='constant', constant_values=0)\n",
    "    indices_bytes = padded_indices.tobytes()\n",
    "\n",
    "    # Ensure that padded data length aligns with expected block size\n",
    "    assert len(indices_bytes) % k == 0, \"Padded data size is not aligned with the block size.\"\n",
    "\n",
    "    # Encode the data\n",
    "    encoded_data = rs.encode(indices_bytes)\n",
    "\n",
    "    # Save encoded data to a .bin file\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(encoded_data)\n",
    "\n",
    "    print(f\"Encoded data saved to {output_file}\")\n",
    "    return len(indices), len(padded_indices), encoded_data\n",
    "\n",
    "# Generate simulated data\n",
    "original_size = 12288  # Original data size (indices count)\n",
    "indices = np.random.randint(0, 256, size=(original_size,), dtype=np.uint8)  # uint8 indices\n",
    "\n",
    "# Transmit the encoded data\n",
    "original_size, padded_size, encoded_data = transmitter(indices, \"transmitted_data.bin\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_noise(input_file, output_file, error_ratio):\n",
    "    \"\"\"\n",
    "    Add noise to the data in a binary file based on a given error ratio.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the input binary file.\n",
    "        output_file (str): Path to save the noisy binary file.\n",
    "        error_ratio (float): Fraction of bits to flip (e.g., 0.01 for 1% of bits).\n",
    "    \n",
    "    Returns:\n",
    "        noisy_data (bytes): The noisy data.\n",
    "    \"\"\"\n",
    "    # Read encoded data from file\n",
    "    with open(input_file, \"rb\") as f:\n",
    "        encoded_data = f.read()\n",
    "\n",
    "    # Calculate the total number of bits in the file\n",
    "    total_bits = len(encoded_data) * 8\n",
    "\n",
    "    # Calculate the number of errors based on the error ratio\n",
    "    num_errors = int(total_bits * error_ratio)\n",
    "    print(f\"Introducing {num_errors} errors out of {total_bits} total bits (ratio = {error_ratio}).\")\n",
    "\n",
    "    # Add noise to the data\n",
    "    noisy_data = bytearray(encoded_data)\n",
    "    for _ in range(num_errors):\n",
    "        byte_index = np.random.randint(len(noisy_data))\n",
    "        bit_index = np.random.randint(8)\n",
    "        noisy_data[byte_index] ^= (1 << bit_index)  # Flip a random bit\n",
    "\n",
    "    # Save the noisy data to a .bin file\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(noisy_data)\n",
    "\n",
    "    print(f\"Noisy data saved to {output_file}\")\n",
    "    return noisy_data\n",
    "\n",
    "\n",
    "\n",
    "def receiver(input_file, output_file, original_size):\n",
    "    # Load noisy data\n",
    "    with open(input_file, \"rb\") as f:\n",
    "        received_data = f.read()\n",
    "\n",
    "    # Decode block by block\n",
    "    def decode_blocks(encoded_data, block_size, data_size, redundancy):\n",
    "        decoded_result = bytearray()\n",
    "        num_blocks = len(encoded_data) // block_size\n",
    "\n",
    "        print(f\"Decoding {num_blocks} blocks of size {block_size} bytes each.\")\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            start = i * block_size\n",
    "            end = start + block_size\n",
    "            block = encoded_data[start:end]\n",
    "\n",
    "            try:\n",
    "                # Attempt to decode the block\n",
    "                decoded_block = rs.decode(block)\n",
    "                if isinstance(decoded_block, tuple):  # Handle tuple output\n",
    "                    decoded_block = decoded_block[0]\n",
    "                decoded_result.extend(decoded_block[:data_size])  # Append only data symbols\n",
    "            except reedsolo.ReedSolomonError:\n",
    "                # Decoding failed, append raw noisy data for this block\n",
    "                print(f\"Block {i + 1} could not be decoded. Retaining noisy data.\")\n",
    "                decoded_result.extend(block[:data_size])  # Append raw data symbols (exclude redundancy)\n",
    "\n",
    "        return decoded_result\n",
    "\n",
    "    # Decode the noisy data\n",
    "    decoded_data = decode_blocks(received_data, block_size=n, data_size=k, redundancy=r)\n",
    "\n",
    "    # Remove padding\n",
    "    decoded_data = decoded_data[:original_size]  # Trim to original data size (bytes)\n",
    "    decoded_indices = np.frombuffer(decoded_data, dtype=np.uint8)\n",
    "\n",
    "    # Save decoded indices to a .bin file\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(decoded_indices.tobytes())\n",
    "\n",
    "    print(f\"Decoded indices saved to {output_file}\")\n",
    "    return decoded_indices\n",
    "\n",
    "# Transmit the data\n",
    "original_size, padded_size, encoded_data = transmitter(indices, \"transmitted_data.bin\")\n",
    "\n",
    "# Simulate noise\n",
    "#noisy_data = add_noise(\"transmitted_data.bin\", \"noisy_data.bin\", num_errors=30)\n",
    "noisy_data = add_noise(\"transmitted_data.bin\", \"noisy_data.bin\", error_ratio= 0.04)\n",
    "\n",
    "\n",
    "# Receive and decode the data\n",
    "decoded_indices = receiver(\"noisy_data.bin\", \"decoded_indices.bin\", original_size)\n",
    "\n",
    "# Validate shapes\n",
    "print(\"\\nDecoded Indices (Best Effort):\")\n",
    "print(decoded_indices)\n",
    "\n",
    "print(\"\\nOriginal Indices:\")\n",
    "print(indices)\n",
    "\n",
    "print(f\"\\nOriginal shape: {indices.shape}, Decoded shape: {decoded_indices.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity: 74.03%\n",
      "Errors: 3191 out of 12288 elements\n"
     ]
    }
   ],
   "source": [
    "# calculate number of similar elements between indices and decoded indices and give percentage\n",
    "\n",
    "def calculate_similarity(indices, decoded_indices):\n",
    "    num_similar = np.sum(indices == decoded_indices)\n",
    "    total_elements = indices.size\n",
    "    similarity = num_similar / total_elements\n",
    "    return similarity, num_similar, total_elements\n",
    "\n",
    "similarity,num_similar, total_elements = calculate_similarity(indices, decoded_indices)\n",
    "print(f\"\\nSimilarity: {similarity:.2%}\")\n",
    "print(f\"Errors: {total_elements - num_similar} out of {total_elements} elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bit Error Rate: 0.00e+00\n",
      "Number of bit errors: 0\n",
      "Total number of bits: 195840\n"
     ]
    }
   ],
   "source": [
    "def calculate_ber(bin_file1, bin_file2):\n",
    "    with open(bin_file1, 'rb') as file1, open(bin_file2, 'rb') as file2:\n",
    "        data1 = file1.read()\n",
    "        data2 = file2.read()\n",
    "    \n",
    "    # Calculate the number of bit errors\n",
    "    bit_errors = sum(bin(int(byte1) ^ int(byte2)).count('1') for byte1, byte2 in zip(data1, data2))\n",
    "    \n",
    "    # Calculate the bit error rate\n",
    "    ber = bit_errors / (8 * len(data1))\n",
    "    return ber, bit_errors, len(data1)*8\n",
    "\n",
    "ber, errors, bits = calculate_ber('transmitted_data.bin', 'transmitted_data_new.bin')\n",
    "print(f\"Bit Error Rate: {ber:.2e}\")\n",
    "print(f\"Number of bit errors: {errors}\")\n",
    "print(f\"Total number of bits: {bits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ber, errors, bits = calculate_ber('encoded_feature_rayleigh_image24.bin', 'corrupted_feature_rayleigh_image24.bin')\n",
    "print(f\"Bit Error Rate: {ber:.2e}\")\n",
    "print(f\"Number of bit errors: {errors}\")\n",
    "print(f\"Total number of bits: {bits}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compact binary file saving method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[414 162 454 469 319]\n"
     ]
    }
   ],
   "source": [
    "from bitarray import bitarray\n",
    "import numpy as np\n",
    "\n",
    "# Example indices array (values between 0 and 511)\n",
    "#indices = np.array([3, 511, 256, 128, 5], dtype=np.uint16)\n",
    "\n",
    "original_size = 5  # Original data size\n",
    "indices = np.random.randint(0, 512, size=(original_size,), dtype=np.uint16)\n",
    "\n",
    "# Convert indices to binary representation\n",
    "bit_stream = bitarray()\n",
    "for index in indices:\n",
    "    bit_stream.extend(format(index, '09b'))  # 9-bit binary format\n",
    "\n",
    "# Save to a binary file\n",
    "with open('indices.bin', 'wb') as f:\n",
    "    bit_stream.tofile(f)\n",
    "\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[414 162 454 469 319]\n"
     ]
    }
   ],
   "source": [
    "from bitarray import bitarray\n",
    "import numpy as np\n",
    "\n",
    "# Read the binary file\n",
    "bit_stream = bitarray()\n",
    "with open('indices.bin', 'rb') as f:\n",
    "    bit_stream.fromfile(f)\n",
    "\n",
    "# Decode indices from the bit stream\n",
    "indices = []\n",
    "i = 0\n",
    "while i + 9 <= len(bit_stream):  # Ensure there are at least 9 bits remaining\n",
    "    indices.append(int(bit_stream[i:i+9].to01(), 2))\n",
    "    i += 9  # Move to the next chunk\n",
    "\n",
    "# Convert to NumPy array for consistency\n",
    "indices_np = np.array(indices, dtype=np.uint16)\n",
    "\n",
    "print(indices_np)  # Output the reconstructed indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 256\n",
    "\n",
    "bits_per_index = int(np.ceil(np.log2(k)))\n",
    "\n",
    "# Load indices from the binary file\n",
    "def load_indices_from_binary(file_path, bits_per_index):\n",
    "    bit_stream = bitarray()\n",
    "    with open(file_path, 'rb') as f:\n",
    "        bit_stream.fromfile(f)\n",
    "    num_indices = len(bit_stream) // bits_per_index  # Calculate the number of indices\n",
    "    indices = [int(bit_stream[i:i+bits_per_index].to01(), 2) for i in range(0, len(bit_stream), bits_per_index)]\n",
    "    return np.array(indices[:num_indices], dtype=np.uint16 if bits_per_index > 8 else np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bitarray('110011110010100010111000110111010101100111111000')"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bit_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiently saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data saved to 'transmitted_data.bin'.\n",
      "\n",
      "Introducing 510 errors out of 10200 total bits (ratio = 0.05).\n",
      "Noisy data saved to 'noisy_data.bin'.\n",
      "Decoding 5 blocks of size 255 bytes each.\n",
      "Block 1 could not be decoded. Retaining noisy data.\n",
      "Block 2 could not be decoded. Retaining noisy data.\n",
      "Block 3 could not be decoded. Retaining noisy data.\n",
      "Block 4 could not be decoded. Retaining noisy data.\n",
      "Block 5 could not be decoded. Retaining noisy data.\n",
      "Recovered indices saved to 'recovered_indices.bin'\n",
      "\n",
      "Decoded Indices (First 20): [256 510 237 195  40 239  69 498 255  74 174 412 500 247 332  36 341 418\n",
      " 264  41]\n",
      "Original Indices (First 20): [388 188 237 193  40 239  77 498 254  74 170 412 372 243 332  36 337 418\n",
      " 266  41]\n",
      "\n",
      "Original shape: (513,), Decoded shape: (513,)\n",
      "\n",
      "Similarity: 65.89%\n",
      "Errors: 175 out of 513 elements.\n"
     ]
    }
   ],
   "source": [
    "from bitarray import bitarray\n",
    "import numpy as np\n",
    "import reedsolo\n",
    "\n",
    "# Initialize RS codec\n",
    "r = 127  # Redundancy (symbols per block)\n",
    "n = 255  # Total symbols per block\n",
    "data_symbols = n - r  # Data symbols per block\n",
    "rs = reedsolo.RSCodec(r)\n",
    "\n",
    "# Parameters\n",
    "original_size = 513  # Original data size\n",
    "k = 512  # Number of clusters (max value for indices)\n",
    "bits_per_index = int(np.ceil(np.log2(k)))  # Calculate bits needed for `k`\n",
    "\n",
    "# === Transmitter ===\n",
    "\n",
    "# Simulated data\n",
    "indices = np.random.randint(0, k, size=(original_size,))\n",
    "\n",
    "# Pack indices into a bit stream\n",
    "bit_stream = bitarray()\n",
    "for index in indices:\n",
    "    bit_stream.extend(format(index, f'0{bits_per_index}b'))\n",
    "\n",
    "# Convert the bit stream to bytes\n",
    "packed_data = bit_stream.tobytes()\n",
    "\n",
    "# Pad for Reed-Solomon compatibility\n",
    "padding_length = (data_symbols - (len(packed_data) % data_symbols)) % data_symbols\n",
    "padded_data = packed_data + bytes(padding_length)\n",
    "\n",
    "# Encode with Reed-Solomon\n",
    "encoded_data = rs.encode(padded_data)\n",
    "\n",
    "# Save the encoded data\n",
    "encoded_file = \"transmitted_data.bin\"\n",
    "with open(encoded_file, \"wb\") as f:\n",
    "    f.write(encoded_data)\n",
    "print(f\"Encoded data saved to '{encoded_file}'.\\n\")\n",
    "\n",
    "# Introduce noise to the encoded data\n",
    "def add_noise_with_ratio(input_file, output_file, error_ratio):\n",
    "    \"\"\"\n",
    "    Add noise to the encoded data in a binary file and save the result.\n",
    "    \"\"\"\n",
    "    with open(input_file, \"rb\") as f:\n",
    "        encoded_data = f.read()\n",
    "\n",
    "    noisy_data = bytearray(encoded_data)\n",
    "    total_bits = len(noisy_data) * 8\n",
    "    num_errors = int(total_bits * error_ratio)\n",
    "\n",
    "    print(f\"Introducing {num_errors} errors out of {total_bits} total bits (ratio = {error_ratio}).\")\n",
    "\n",
    "    for _ in range(num_errors):\n",
    "        byte_index = np.random.randint(len(noisy_data))\n",
    "        bit_index = np.random.randint(8)\n",
    "        noisy_data[byte_index] ^= (1 << bit_index)\n",
    "\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(noisy_data)\n",
    "\n",
    "    print(f\"Noisy data saved to '{output_file}'.\")\n",
    "    return noisy_data\n",
    "\n",
    "noisy_file = \"noisy_data.bin\"\n",
    "noisy_data = add_noise_with_ratio(encoded_file, noisy_file, error_ratio=0.05)\n",
    "\n",
    "# === Receiver ===\n",
    "\n",
    "# Decode Reed-Solomon blocks\n",
    "def decode_blocks(input_file, block_size, data_size, original_size, bits_per_index):\n",
    "    \"\"\"\n",
    "    Decode noisy data from a binary file and reconstruct the original indices.\n",
    "    \"\"\"\n",
    "    decoded_result = bytearray()\n",
    "\n",
    "    with open(input_file, \"rb\") as f:\n",
    "        encoded_data = f.read()\n",
    "\n",
    "    num_blocks = len(encoded_data) // block_size\n",
    "    print(f\"Decoding {num_blocks} blocks of size {block_size} bytes each.\")\n",
    "\n",
    "    for i in range(num_blocks):\n",
    "        start = i * block_size\n",
    "        end = start + block_size\n",
    "        block = encoded_data[start:end]\n",
    "\n",
    "        try:\n",
    "            decoded_block = rs.decode(block)\n",
    "            if isinstance(decoded_block, tuple):\n",
    "                decoded_block = decoded_block[0]\n",
    "            decoded_result.extend(decoded_block[:data_symbols])\n",
    "        except reedsolo.ReedSolomonError:\n",
    "            print(f\"Block {i + 1} could not be decoded. Retaining noisy data.\")\n",
    "            decoded_result.extend(block[:data_symbols])\n",
    "\n",
    "    # Remove padding\n",
    "    decoded_data = decoded_result[:len(decoded_result) - padding_length]\n",
    "\n",
    "    # Convert decoded bytes back into a bit stream\n",
    "    bit_stream = bitarray()\n",
    "    bit_stream.frombytes(decoded_data)\n",
    "\n",
    "    # Decode indices from the bit stream\n",
    "    indices_decoded = []\n",
    "    i = 0\n",
    "    while i + bits_per_index <= len(bit_stream):\n",
    "        indices_decoded.append(int(bit_stream[i:i+bits_per_index].to01(), 2))\n",
    "        i += bits_per_index\n",
    "\n",
    "    return np.array(indices_decoded[:original_size], dtype=np.uint16 if bits_per_index > 8 else np.uint8)\n",
    "\n",
    "decoded_indices = decode_blocks(noisy_file, block_size=n, data_size=data_symbols, original_size=original_size, bits_per_index=bits_per_index)\n",
    "\n",
    "# Save recovered indices to a compact binary file\n",
    "def save_indices_to_binary(indices_np, bits_per_index, file_path):\n",
    "    \"\"\"\n",
    "    Save indices to a compact binary file using the required number of bits per index.\n",
    "    \"\"\"\n",
    "    packed_data = bitarray()\n",
    "    for idx in indices_np:\n",
    "        packed_data.extend(format(idx, f'0{bits_per_index}b'))  # Pack indices into binary format\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        packed_data.tofile(f)\n",
    "    print(f\"Recovered indices saved to '{file_path}'\")\n",
    "\n",
    "recovered_file = \"recovered_indices.bin\"\n",
    "save_indices_to_binary(decoded_indices, bits_per_index, recovered_file)\n",
    "\n",
    "# Validate results\n",
    "print(\"\\nDecoded Indices (First 20):\", decoded_indices[:20])\n",
    "print(\"Original Indices (First 20):\", indices[:20])\n",
    "\n",
    "# Validate shapes and similarity\n",
    "print(f\"\\nOriginal shape: {indices.shape}, Decoded shape: {decoded_indices.shape}\")\n",
    "num_similar = np.sum(indices == decoded_indices)\n",
    "total_elements = indices.size\n",
    "similarity = num_similar / total_elements\n",
    "print(f\"\\nSimilarity: {similarity:.2%}\")\n",
    "print(f\"Errors: {total_elements - num_similar} out of {total_elements} elements.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hamming Distance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 12,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 10,\n",
       " 11,\n",
       " 9,\n",
       " 8,\n",
       " 24,\n",
       " 25,\n",
       " 27,\n",
       " 26,\n",
       " 30,\n",
       " 31,\n",
       " 29,\n",
       " 28,\n",
       " 20,\n",
       " 21,\n",
       " 23,\n",
       " 22,\n",
       " 18,\n",
       " 19,\n",
       " 17,\n",
       " 16,\n",
       " 48,\n",
       " 49,\n",
       " 51,\n",
       " 50,\n",
       " 54,\n",
       " 55,\n",
       " 53,\n",
       " 52,\n",
       " 60,\n",
       " 61,\n",
       " 63,\n",
       " 62,\n",
       " 58,\n",
       " 59,\n",
       " 57,\n",
       " 56,\n",
       " 40,\n",
       " 41,\n",
       " 43,\n",
       " 42,\n",
       " 46,\n",
       " 47,\n",
       " 45,\n",
       " 44,\n",
       " 36,\n",
       " 37,\n",
       " 39,\n",
       " 38,\n",
       " 34,\n",
       " 35,\n",
       " 33,\n",
       " 32,\n",
       " 96,\n",
       " 97,\n",
       " 99,\n",
       " 98,\n",
       " 102,\n",
       " 103,\n",
       " 101,\n",
       " 100,\n",
       " 108,\n",
       " 109,\n",
       " 111,\n",
       " 110,\n",
       " 106,\n",
       " 107,\n",
       " 105,\n",
       " 104,\n",
       " 120,\n",
       " 121,\n",
       " 123,\n",
       " 122,\n",
       " 126,\n",
       " 127,\n",
       " 125,\n",
       " 124,\n",
       " 116,\n",
       " 117,\n",
       " 119,\n",
       " 118,\n",
       " 114,\n",
       " 115,\n",
       " 113,\n",
       " 112,\n",
       " 80,\n",
       " 81,\n",
       " 83,\n",
       " 82,\n",
       " 86,\n",
       " 87,\n",
       " 85,\n",
       " 84,\n",
       " 92,\n",
       " 93,\n",
       " 95,\n",
       " 94,\n",
       " 90,\n",
       " 91,\n",
       " 89,\n",
       " 88,\n",
       " 72,\n",
       " 73,\n",
       " 75,\n",
       " 74,\n",
       " 78,\n",
       " 79,\n",
       " 77,\n",
       " 76,\n",
       " 68,\n",
       " 69,\n",
       " 71,\n",
       " 70,\n",
       " 66,\n",
       " 67,\n",
       " 65,\n",
       " 64,\n",
       " 192,\n",
       " 193,\n",
       " 195,\n",
       " 194,\n",
       " 198,\n",
       " 199,\n",
       " 197,\n",
       " 196,\n",
       " 204,\n",
       " 205,\n",
       " 207,\n",
       " 206,\n",
       " 202,\n",
       " 203,\n",
       " 201,\n",
       " 200,\n",
       " 216,\n",
       " 217,\n",
       " 219,\n",
       " 218,\n",
       " 222,\n",
       " 223,\n",
       " 221,\n",
       " 220,\n",
       " 212,\n",
       " 213,\n",
       " 215,\n",
       " 214,\n",
       " 210,\n",
       " 211,\n",
       " 209,\n",
       " 208,\n",
       " 240,\n",
       " 241,\n",
       " 243,\n",
       " 242,\n",
       " 246,\n",
       " 247,\n",
       " 245,\n",
       " 244,\n",
       " 252,\n",
       " 253,\n",
       " 255,\n",
       " 254,\n",
       " 250,\n",
       " 251,\n",
       " 249,\n",
       " 248,\n",
       " 232,\n",
       " 233,\n",
       " 235,\n",
       " 234,\n",
       " 238,\n",
       " 239,\n",
       " 237,\n",
       " 236,\n",
       " 228,\n",
       " 229,\n",
       " 231,\n",
       " 230,\n",
       " 226,\n",
       " 227,\n",
       " 225,\n",
       " 224,\n",
       " 160,\n",
       " 161,\n",
       " 163,\n",
       " 162,\n",
       " 166,\n",
       " 167,\n",
       " 165,\n",
       " 164,\n",
       " 172,\n",
       " 173,\n",
       " 175,\n",
       " 174,\n",
       " 170,\n",
       " 171,\n",
       " 169,\n",
       " 168,\n",
       " 184,\n",
       " 185,\n",
       " 187,\n",
       " 186,\n",
       " 190,\n",
       " 191,\n",
       " 189,\n",
       " 188,\n",
       " 180,\n",
       " 181,\n",
       " 183,\n",
       " 182,\n",
       " 178,\n",
       " 179,\n",
       " 177,\n",
       " 176,\n",
       " 144,\n",
       " 145,\n",
       " 147,\n",
       " 146,\n",
       " 150,\n",
       " 151,\n",
       " 149,\n",
       " 148,\n",
       " 156,\n",
       " 157,\n",
       " 159,\n",
       " 158,\n",
       " 154,\n",
       " 155,\n",
       " 153,\n",
       " 152,\n",
       " 136,\n",
       " 137,\n",
       " 139,\n",
       " 138,\n",
       " 142,\n",
       " 143,\n",
       " 141,\n",
       " 140,\n",
       " 132,\n",
       " 133,\n",
       " 135,\n",
       " 134,\n",
       " 130,\n",
       " 131,\n",
       " 129,\n",
       " 128,\n",
       " 384,\n",
       " 385,\n",
       " 387,\n",
       " 386,\n",
       " 390,\n",
       " 391,\n",
       " 389,\n",
       " 388,\n",
       " 396,\n",
       " 397,\n",
       " 399,\n",
       " 398,\n",
       " 394,\n",
       " 395,\n",
       " 393,\n",
       " 392,\n",
       " 408,\n",
       " 409,\n",
       " 411,\n",
       " 410,\n",
       " 414,\n",
       " 415,\n",
       " 413,\n",
       " 412,\n",
       " 404,\n",
       " 405,\n",
       " 407,\n",
       " 406,\n",
       " 402,\n",
       " 403,\n",
       " 401,\n",
       " 400,\n",
       " 432,\n",
       " 433,\n",
       " 435,\n",
       " 434,\n",
       " 438,\n",
       " 439,\n",
       " 437,\n",
       " 436,\n",
       " 444,\n",
       " 445,\n",
       " 447,\n",
       " 446,\n",
       " 442,\n",
       " 443,\n",
       " 441,\n",
       " 440,\n",
       " 424,\n",
       " 425,\n",
       " 427,\n",
       " 426,\n",
       " 430,\n",
       " 431,\n",
       " 429,\n",
       " 428,\n",
       " 420,\n",
       " 421,\n",
       " 423,\n",
       " 422,\n",
       " 418,\n",
       " 419,\n",
       " 417,\n",
       " 416,\n",
       " 480,\n",
       " 481,\n",
       " 483,\n",
       " 482,\n",
       " 486,\n",
       " 487,\n",
       " 485,\n",
       " 484,\n",
       " 492,\n",
       " 493,\n",
       " 495,\n",
       " 494,\n",
       " 490,\n",
       " 491,\n",
       " 489,\n",
       " 488,\n",
       " 504,\n",
       " 505,\n",
       " 507,\n",
       " 506,\n",
       " 510,\n",
       " 511,\n",
       " 509,\n",
       " 508,\n",
       " 500,\n",
       " 501,\n",
       " 503,\n",
       " 502,\n",
       " 498,\n",
       " 499,\n",
       " 497,\n",
       " 496,\n",
       " 464,\n",
       " 465,\n",
       " 467,\n",
       " 466,\n",
       " 470,\n",
       " 471,\n",
       " 469,\n",
       " 468,\n",
       " 476,\n",
       " 477,\n",
       " 479,\n",
       " 478,\n",
       " 474,\n",
       " 475,\n",
       " 473,\n",
       " 472,\n",
       " 456,\n",
       " 457,\n",
       " 459,\n",
       " 458,\n",
       " 462,\n",
       " 463,\n",
       " 461,\n",
       " 460,\n",
       " 452,\n",
       " 453,\n",
       " 455,\n",
       " 454,\n",
       " 450,\n",
       " 451,\n",
       " 449,\n",
       " 448,\n",
       " 320,\n",
       " 321,\n",
       " 323,\n",
       " 322,\n",
       " 326,\n",
       " 327,\n",
       " 325,\n",
       " 324,\n",
       " 332,\n",
       " 333,\n",
       " 335,\n",
       " 334,\n",
       " 330,\n",
       " 331,\n",
       " 329,\n",
       " 328,\n",
       " 344,\n",
       " 345,\n",
       " 347,\n",
       " 346,\n",
       " 350,\n",
       " 351,\n",
       " 349,\n",
       " 348,\n",
       " 340,\n",
       " 341,\n",
       " 343,\n",
       " 342,\n",
       " 338,\n",
       " 339,\n",
       " 337,\n",
       " 336,\n",
       " 368,\n",
       " 369,\n",
       " 371,\n",
       " 370,\n",
       " 374,\n",
       " 375,\n",
       " 373,\n",
       " 372,\n",
       " 380,\n",
       " 381,\n",
       " 383,\n",
       " 382,\n",
       " 378,\n",
       " 379,\n",
       " 377,\n",
       " 376,\n",
       " 360,\n",
       " 361,\n",
       " 363,\n",
       " 362,\n",
       " 366,\n",
       " 367,\n",
       " 365,\n",
       " 364,\n",
       " 356,\n",
       " 357,\n",
       " 359,\n",
       " 358,\n",
       " 354,\n",
       " 355,\n",
       " 353,\n",
       " 352,\n",
       " 288,\n",
       " 289,\n",
       " 291,\n",
       " 290,\n",
       " 294,\n",
       " 295,\n",
       " 293,\n",
       " 292,\n",
       " 300,\n",
       " 301,\n",
       " 303,\n",
       " 302,\n",
       " 298,\n",
       " 299,\n",
       " 297,\n",
       " 296,\n",
       " 312,\n",
       " 313,\n",
       " 315,\n",
       " 314,\n",
       " 318,\n",
       " 319,\n",
       " 317,\n",
       " 316,\n",
       " 308,\n",
       " 309,\n",
       " 311,\n",
       " 310,\n",
       " 306,\n",
       " 307,\n",
       " 305,\n",
       " 304,\n",
       " 272,\n",
       " 273,\n",
       " 275,\n",
       " 274,\n",
       " 278,\n",
       " 279,\n",
       " 277,\n",
       " 276,\n",
       " 284,\n",
       " 285,\n",
       " 287,\n",
       " 286,\n",
       " 282,\n",
       " 283,\n",
       " 281,\n",
       " 280,\n",
       " 264,\n",
       " 265,\n",
       " 267,\n",
       " 266,\n",
       " 270,\n",
       " 271,\n",
       " 269,\n",
       " 268,\n",
       " 260,\n",
       " 261,\n",
       " 263,\n",
       " 262,\n",
       " 258,\n",
       " 259,\n",
       " 257,\n",
       " 256]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def int_to_gray(n):\n",
    "    return n ^ (n >> 1)\n",
    "\n",
    "def generate_gray_codes(K):\n",
    "    gray_codes = [int_to_gray(i) for i in range(K)]\n",
    "    return gray_codes\n",
    "\n",
    "K = 512  # Number of clusters\n",
    "gray_codes = generate_gray_codes(K)\n",
    "\n",
    "gray_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
