{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tharu\\AppData\\Local\\Temp\\ipykernel_10288\\569774741.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  indices = torch.load('indices.pt')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the tensor\n",
    "indices = torch.load('indices.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_np = indices.numpy()  # Convert PyTorch tensor to NumPy array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100, 329, 122,  67, 288, 126, 128, 140, 460, 372])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uint 16 for k=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding 6 blocks of size 255 bytes each.\n",
      "Block 5 could not be decoded. Retaining noisy data.\n",
      "Decoded Indices (Best Effort):\n",
      "[  394   290   165   493    23   129   121   285   113   427   393    23\n",
      "    77   229   419   188    82   265   297   125   450   283   457   128\n",
      "   455   213   424   295   302   286    29   119   402   315   436   107\n",
      "   429   378   243    69   229   280   316   275    84   476   238   283\n",
      "   113    20   466   287   453   372    44   256   255   377    51   185\n",
      "   393   392   373   493    38   158     7    50   365   414    16   246\n",
      "   170   197   336   195   403   509   130   298   128   375   135   450\n",
      "   381   406   283    28    19   237   472   433   167   286   131   421\n",
      "   291    91   188   281   209   226   412   236    21   457   484   350\n",
      "   108   263   179    64   101    87   374    35   388   480   135    13\n",
      "   329   271    13   116   132   172   330   188   102   119   387   240\n",
      "   466   212   415   501   253   480    21   250   149   331   210   423\n",
      "   253   466   388   113    16   185   193   414   224   437   247    14\n",
      "     7   432   458    37   284   227   260   154    12   473   429   324\n",
      "   206    84   135   142   364   501   339   231    26   337    87   134\n",
      "    49    50   363   220   165    30   486    35   215   435   242   490\n",
      "   260    63    47    95   151   237   412   176   281   404   345   254\n",
      "   308     7   244   349   460    22   341   285     7   182   120   143\n",
      "    27   440   134   360   276    66   156    23   376 51197     1   394\n",
      "   438   207   416   148   444    62   373   301   365   116   106   303\n",
      "    79   298   381   491   444   190   140    96   157   292   390   312\n",
      "   189    80    11   508   442   373   344   500   224    25   189    23\n",
      "   430   348   331    99   213   435   503   150   233   234   105    74\n",
      "   266   481    19   355   486   450   360   311   314   384   400   380\n",
      "   348   416    89  1498    42   243   416   195   249   124   276   103\n",
      "    93   248   162   348   504   188   181   498   156   441   451   253\n",
      "   404   173   124  8516    40   441   423   145    56   168    83    67\n",
      "   390   231   132    98   348   457   225   394    51   260   375   276\n",
      "   339   177    55    91    92   152   192   205   193   403    89   241\n",
      " 33158   168   450   436    82   426   265   472   414   422   370   109\n",
      "    18   200    19   193   332    92   361   176   373   302   265   349\n",
      "   146   501   479     7   305   429   459   487    17   385     1   276\n",
      "   184   387   378   252   473   211    83   391   169   465   494   350\n",
      "   253   468   171    85   463   173   307   222     9    38   268   434\n",
      "   450    94   352   409   426    34   137   201   185   272    66   228\n",
      "   413    96   299   114   298    80    75   487    97   505   111   498\n",
      "   195   120   215   175    89   379   418   398   186   459   390   243\n",
      "   141    51    51   469   458   148   330   206   175   390   342   219\n",
      "   330     9   104   178   318   357     2   129   129   471   479   441\n",
      "   240   187   257   284   494   344   137   149   211   377   373   200\n",
      "   199   430   264    49   231   424   491   215   498   325   247    43\n",
      "   454    62   254   406    44   436   425   179   200    36   276   219]\n",
      "\n",
      "Original Indices:\n",
      "[394 290 165 493  23 129 121 285 113 427 393  23  77 229 419 188  82 265\n",
      " 297 125 450 283 457 128 455 213 424 295 302 286  29 119 402 315 436 107\n",
      " 429 378 243  69 229 280 316 275  84 476 238 283 113  20 466 287 453 372\n",
      "  44 256 255 377  51 185 393 392 373 493  38 158   7  50 365 414  16 246\n",
      " 170 197 336 195 403 509 130 298 128 375 135 450 381 406 283  28  19 237\n",
      " 472 433 167 286 131 421 291  91 188 281 209 226 412 236  21 457 484 350\n",
      " 108 263 179  64 101  87 374  35 388 480 135  13 329 271  13 116 132 172\n",
      " 330 188 102 119 387 240 466 212 415 501 125 480  21 250 149 331 210 423\n",
      " 253 466 388 113  16 185 193 414 224 437 247  14   7 432 458  37 284 227\n",
      " 260 154  12 473 429 324 206  84 135 142 364 501 339 164  26 337  87 134\n",
      "  49  50 363 220 165  30 486  35 215 435 242 490 260  63  47  95 151 237\n",
      " 412 176 281 405 345 254 308   7 244 349 460  22 341 285   7 182 120 143\n",
      "  27 440 134 360 276  66 156  22 376 253   1 394 438 207 416 148 444  62\n",
      " 373 297 365 116 106 303  79 298 381 491 444 190 140  96 157 292 390 312\n",
      " 189  80  11 508 442 373 344 500 224  25 189  23 430 348 331  99 213 435\n",
      " 503 150 233 234 105  74 266 481  19 355 486 450 360 311 447 384 400 380\n",
      " 350 416  89 474  42 243 416 195 249 124 404 103  93 248 162 348 504 188\n",
      " 181 498 156 441 451 253 404 173 124 324  40 441 423 145  56 168  83  67\n",
      " 390 231 132  98 348 457 225 394  51 260 375 276 339 177  55  91  92 152\n",
      " 192 205 193 403  89 241 390 168 450 436 242 426 265 472 414 420 370 109\n",
      "  18 200  19 193 332  92 360 176 373 302 265 349 146 501 479   7 305 429\n",
      " 459 487  17 385   1 276 184 387 378 252 473 211  83 391 169 465 494 350\n",
      " 253 468 171  85 463 173 307 222   9  38 268 434 450  94 352 409 426  34\n",
      " 137 201 185 272  66 228 413  96 299 114 298  80  75 487  97 505 111 498\n",
      " 195 120 215 175  89 379 418 398 186 459 390 243 141  51  51 469 458 148\n",
      " 330 206 175 390 342 219 330   9 104 178 318 357   2 129 129 471 479 441\n",
      " 240 187 257 284 494 344 137 149 211 377 373 200 199 430 264  49 231 424\n",
      " 491 215 498 325 247  43 454  62 254 406  44 436 425 179 200  36 276 219]\n",
      "\n",
      "Original shape: (504,), Decoded shape: (504,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import reedsolo\n",
    "\n",
    "# Initialize RS codec\n",
    "r = 4  # Redundancy (4 symbols per block)\n",
    "n = 255  # Total symbols per block\n",
    "k = n - r  # Data symbols per block\n",
    "rs = reedsolo.RSCodec(r)\n",
    "\n",
    "# Simulated data\n",
    "original_size = 504 # Original data size\n",
    "indices = np.random.randint(0, 512, size=(original_size,), dtype=np.uint16)\n",
    "\n",
    "# Calculate padding\n",
    "padding_length = (k - (len(indices) % k)) % k\n",
    "padded_indices = np.pad(indices, (0, padding_length), mode='constant', constant_values=0)\n",
    "indices_bytes = padded_indices.tobytes()\n",
    "\n",
    "# Ensure that padded data length aligns with expected block size\n",
    "assert len(indices_bytes) % k == 0, \"Padded data size is not aligned with the block size.\"\n",
    "\n",
    "# Encode the data\n",
    "encoded_data = rs.encode(indices_bytes)\n",
    "\n",
    "# Simulate noise (add random bit errors)\n",
    "def add_noise(data, num_errors):\n",
    "    noisy_data = bytearray(data)\n",
    "    for _ in range(num_errors):\n",
    "        byte_index = np.random.randint(len(noisy_data))\n",
    "        bit_index = np.random.randint(8)\n",
    "        noisy_data[byte_index] ^= (1 << bit_index)  # Flip a random bit\n",
    "    return bytes(noisy_data)\n",
    "\n",
    "noisy_data = add_noise(encoded_data, num_errors=20)  # Add errors across blocks\n",
    "\n",
    "# Process data block by block\n",
    "def decode_blocks(encoded_data, block_size, data_size, redundancy):\n",
    "    decoded_result = bytearray()\n",
    "    num_blocks = len(encoded_data) // block_size\n",
    "\n",
    "    print(f\"Decoding {num_blocks} blocks of size {block_size} bytes each.\")\n",
    "\n",
    "    for i in range(num_blocks):\n",
    "        start = i * block_size\n",
    "        end = start + block_size\n",
    "        block = encoded_data[start:end]\n",
    "\n",
    "        try:\n",
    "            # Attempt to decode the block\n",
    "            decoded_block = rs.decode(block)\n",
    "            if isinstance(decoded_block, tuple):  # Handle tuple output\n",
    "                decoded_block = decoded_block[0]\n",
    "            decoded_result.extend(decoded_block[:data_size])  # Append only data symbols\n",
    "        except reedsolo.ReedSolomonError:\n",
    "            # Decoding failed, append raw noisy data for this block\n",
    "            print(f\"Block {i + 1} could not be decoded. Retaining noisy data.\")\n",
    "            decoded_result.extend(block[:data_size])  # Append raw data symbols (exclude redundancy)\n",
    "\n",
    "    return decoded_result\n",
    "\n",
    "# Decode the noisy data\n",
    "decoded_data = decode_blocks(noisy_data, block_size=n, data_size=k, redundancy=r)\n",
    "\n",
    "# Remove padding\n",
    "decoded_data = decoded_data[:original_size * 2]  # Trim to original data size (bytes)\n",
    "decoded_indices = np.frombuffer(decoded_data, dtype=np.uint16)\n",
    "\n",
    "# Validate shapes\n",
    "print(\"Decoded Indices (Best Effort):\")\n",
    "print(decoded_indices)\n",
    "\n",
    "print(\"\\nOriginal Indices:\")\n",
    "print(indices)\n",
    "\n",
    "print(f\"\\nOriginal shape: {indices.shape}, Decoded shape: {decoded_indices.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uint 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing 204 errors out of 8160 total bits (ratio = 0.025).\n",
      "Decoding 4 blocks of size 255 bytes each.\n",
      "Decoded Indices (Best Effort):\n",
      "[196 240   4 104 239 171 149 214 157 101 177  85 208 157 171 129 124 229\n",
      "  42 106 165 164 245 167 247 244  54  18  43 102 196 242  82  79  23 111\n",
      "   9   2  21  40 186 120 214  27 105  58 110 121 193  60 199  87 189 174\n",
      " 218 209 186 186 134  99 188 207  93 186  36  55 138 113 201 112 244 129\n",
      "  40 235 112 207 183  62 135  62 225 166 120 193 138  28 167 131   0 132\n",
      "  62 157  15  56 135  91 125 117 167 239   6 199 218 240 117 104  50 170\n",
      " 157 235 250  72 230  10 218 231 152 143 197  52 129 189 168  15  91  31\n",
      " 230 231 240 120  29 227  18 125 227  53  81 150  75  16  50 128   9 144\n",
      "  54 177 125 176 231  58 174  38 147 196  84 165 106 203 136 126 200 133\n",
      " 150  35 210 200 140  17 214  62 234 178 184  89 158  71  55  88 159  43\n",
      "  36 229 185  90 175  59 218 215 165  57 198 181   1  38 121 185  38  81\n",
      " 215  70 233 229 231 250  55  97 202 150 161  76   9   5 159 235 250 158\n",
      "   0 159 131 243 157 158  66  57 200 194  56   9 252 206  82 178 141 210\n",
      " 203 205 152  24 223 239 214  82  32 198  65 207  61 239  63 107  46 118\n",
      " 119  33 142  82 120 246  73 121 139 121 159  95   6  85  70   3 165 110\n",
      "  29  54 219  15  94  35 108 230 123 140 220 194  46 168 212 183 112  40\n",
      " 138 119  44 161 176 161 152 212 209  79 250  44  23 169 231  13 247 105\n",
      " 155  84 193  90 252 230  74 224 168  42 152 119 108 128  59  96  67  72\n",
      "  46 235 177 101 197 207  97 207 107  35 240 114 166  50   5 127 201 147\n",
      "  82 213 118   2 174   6 172 113 212  61 142  93 172 251 203 175 232  84\n",
      " 214 153 233  97  70 213 113 255 215  26 205 243 239 154 203  74 215  24\n",
      " 110  17  61 215  10 232 101  98 190  75 204  66 131 174  87 146  46 171\n",
      " 220 174 247 136  43  22 175  86 211 146 166  36  95  46 200 141 192 113\n",
      "  22 240 171  31 167  11 108 166 102   1 123 247 206   4  71 242 202 142\n",
      " 222  46 153 123 188 216 237 102 135 207 136 184  14 132 186  58  89 136\n",
      "  87  86  68 221 137 112  47 195   7 225 224  68 222 214 217 197 133  70\n",
      "   7 210 110 157 163 144 127 101  38 126  22  18  20 178 184 154   4 217\n",
      "  60  78   9 166 125 140  86 123 145 225  30 237 186 230  56 253 147]\n",
      "\n",
      "Original Indices:\n",
      "[196 240   4 104 239 171 149 214 157 101 177  85 208 157 171 129 124 229\n",
      "  42 106 165 164 245 167 247 244  54  18  43 102 196 242  82  79  23 111\n",
      "   9   2  21  40 186 120 214  27 105  58 110 121 193  60 199  87 189 174\n",
      " 218 209 186 186 134  99 188 207  93 186  36  55 138 113 201 112 244 129\n",
      "  40 235 112 207 183  62 135  62 225 166 120 193 138  28 167 131   0 132\n",
      "  62 157  15  56 135  91 125 117 167 239   6 199 218 240 117 104  50 170\n",
      " 157 235 250  72 230  10 218 231 152 143 197  52 129 189 168  15  91  31\n",
      " 230 231 240 120  29 227  18 125 227  53  81 150  75  16  50 128   9 144\n",
      "  54 177 125 176 231  58 174  38 147 196  84 165 106 203 136 126 200 133\n",
      " 150  35 210 200 140  17 214  62 234 178 184  89 158  71  55  88 159  43\n",
      "  36 229 185  90 175  59 218 215 165  57 198 181   1  38 121 185  38  81\n",
      " 215  70 233 229 231 250  55  97 202 150 161  76   9   5 159 235 250 158\n",
      "   0 159 131 243 157 158  66  57 200 194  56   9 252 206  82 178 141 210\n",
      " 203 205 152  24 223 239 214  82  32 198  65 207  61 239  63 107  46 118\n",
      " 119  33 142  82 120 246  73 121 139 121 159  95   6  85  70   3 165 110\n",
      "  29  54 219  15  94  35 108 230 123 140 220 194  46 168 212 183 112  40\n",
      " 138 119  44 161 176 161 152 212 209  79 250  44  23 169 231  13 247 105\n",
      " 155  84 193  90 252 230  74 224 168  42 152 119 108 128  59  96  67  72\n",
      "  46 235 177 101 197 207  97 207 107  35 240 114 166  50   5 127 201 147\n",
      "  82 213 118   2 174   6 172 113 212  61 142  93 172 251 203 175 232  84\n",
      " 214 153 233  97  70 213 113 255 215  26 205 243 239 154 203  74 215  24\n",
      " 110  17  61 215  10 232 101  98 190  75 204  66 131 174  87 146  46 171\n",
      " 220 174 247 136  43  22 175  86 211 146 166  36  95  46 200 141 192 113\n",
      "  22 240 171  31 167  11 108 166 102   1 123 247 206   4  71 242 202 142\n",
      " 222  46 153 123 188 216 237 102 135 207 136 184  14 132 186  58  89 136\n",
      "  87  86  68 221 137 112  47 195   7 225 224  68 222 214 217 197 133  70\n",
      "   7 210 110 157 163 144 127 101  38 126  22  18  20 178 184 154   4 217\n",
      "  60  78   9 166 125 140  86 123 145 225  30 237 186 230  56 253 147]\n",
      "\n",
      "Original shape: (503,), Decoded shape: (503,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import reedsolo\n",
    "\n",
    "# Initialize RS codec\n",
    "r = 120  # Redundancy (4 symbols per block)\n",
    "n = 255  # Total symbols per block\n",
    "k = n - r  # Data symbols per block\n",
    "rs = reedsolo.RSCodec(r)\n",
    "\n",
    "# Simulated data\n",
    "original_size = 503  # Original data size\n",
    "indices = np.random.randint(0, 256, size=(original_size,), dtype=np.uint8)  # uint8 indices\n",
    "\n",
    "# Calculate padding\n",
    "padding_length = (k - (len(indices) % k)) % k  # Padding to align data size to block size\n",
    "padded_indices = np.pad(indices, (0, padding_length), mode='constant', constant_values=0)\n",
    "indices_bytes = padded_indices.tobytes()\n",
    "\n",
    "# Ensure that padded data length aligns with expected block size\n",
    "assert len(indices_bytes) % k == 0, \"Padded data size is not aligned with the block size.\"\n",
    "\n",
    "# Encode the data\n",
    "encoded_data = rs.encode(indices_bytes)\n",
    "\n",
    "# # Simulate noise (add random bit errors)\n",
    "# def add_noise(data, num_errors):\n",
    "#     noisy_data = bytearray(data)\n",
    "#     for _ in range(num_errors):\n",
    "#         byte_index = np.random.randint(len(noisy_data))\n",
    "#         bit_index = np.random.randint(8)\n",
    "#         noisy_data[byte_index] ^= (1 << bit_index)  # Flip a random bit\n",
    "#     return bytes(noisy_data)\n",
    "\n",
    "# noisy_data = add_noise(encoded_data, num_errors=20)  # Add errors across blocks\n",
    "\n",
    "# Simulate noise (add random bit errors based on error ratio)\n",
    "def add_noise_with_ratio(data, error_ratio):\n",
    "    \"\"\"\n",
    "    Add noise to the encoded data by flipping bits based on the error ratio.\n",
    "\n",
    "    Args:\n",
    "        data (bytes): Encoded data.\n",
    "        error_ratio (float): Fraction of bits to flip (e.g., 0.01 for 1% errors).\n",
    "\n",
    "    Returns:\n",
    "        bytes: Noisy data.\n",
    "    \"\"\"\n",
    "    noisy_data = bytearray(data)\n",
    "    total_bits = len(noisy_data) * 8  # Total number of bits in the data\n",
    "    num_errors = int(total_bits * error_ratio)  # Calculate the number of bits to flip\n",
    "\n",
    "    print(f\"Introducing {num_errors} errors out of {total_bits} total bits (ratio = {error_ratio}).\")\n",
    "\n",
    "    for _ in range(num_errors):\n",
    "        byte_index = np.random.randint(len(noisy_data))  # Random byte index\n",
    "        bit_index = np.random.randint(8)  # Random bit within the byte\n",
    "        noisy_data[byte_index] ^= (1 << bit_index)  # Flip the selected bit\n",
    "\n",
    "    return bytes(noisy_data)\n",
    "\n",
    "# Introduce noise with a given error ratio\n",
    "error_ratio = 0.025  # Flip 1% of the total bits\n",
    "noisy_data = add_noise_with_ratio(encoded_data, error_ratio)\n",
    "\n",
    "# Process data block by block\n",
    "def decode_blocks(encoded_data, block_size, data_size, redundancy):\n",
    "    decoded_result = bytearray()\n",
    "    num_blocks = len(encoded_data) // block_size\n",
    "\n",
    "    print(f\"Decoding {num_blocks} blocks of size {block_size} bytes each.\")\n",
    "\n",
    "    for i in range(num_blocks):\n",
    "        start = i * block_size\n",
    "        end = start + block_size\n",
    "        block = encoded_data[start:end]\n",
    "\n",
    "        try:\n",
    "            # Attempt to decode the block\n",
    "            decoded_block = rs.decode(block)\n",
    "            if isinstance(decoded_block, tuple):  # Handle tuple output\n",
    "                decoded_block = decoded_block[0]\n",
    "            decoded_result.extend(decoded_block[:data_size])  # Append only data symbols\n",
    "        except reedsolo.ReedSolomonError:\n",
    "            # Decoding failed, append raw noisy data for this block\n",
    "            print(f\"Block {i + 1} could not be decoded. Retaining noisy data.\")\n",
    "            decoded_result.extend(block[:data_size])  # Append raw data symbols (exclude redundancy)\n",
    "\n",
    "    return decoded_result\n",
    "\n",
    "# Decode the noisy data\n",
    "decoded_data = decode_blocks(noisy_data, block_size=n, data_size=k, redundancy=r)\n",
    "\n",
    "# Remove padding\n",
    "decoded_data = decoded_data[:original_size]  # Trim to original data size (bytes)\n",
    "decoded_indices = np.frombuffer(decoded_data, dtype=np.uint8)\n",
    "\n",
    "# Validate shapes\n",
    "print(\"Decoded Indices (Best Effort):\")\n",
    "print(decoded_indices)\n",
    "\n",
    "print(\"\\nOriginal Indices:\")\n",
    "print(indices)\n",
    "\n",
    "print(f\"\\nOriginal shape: {indices.shape}, Decoded shape: {decoded_indices.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transmitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transmitter for swin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data saved to indices_ec_4d_256k_img22.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tharu\\AppData\\Local\\Temp\\ipykernel_29956\\2663710079.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  indices = torch.load('indices_4d_256k.pt')   # Getting indices from that\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import reedsolo\n",
    "\n",
    "\n",
    "#indices, _ = encode_image_with_nd_codebook(net, codebook_path, test_image_path, config, device, chunk_size)\n",
    "\n",
    "indices = torch.load('indices_4d_256k.pt')   # Getting indices from that\n",
    "indices_np = indices.numpy()  # Convert PyTorch tensor to NumPy array  - This is stored in int64\n",
    "\n",
    "indices_np = indices_np.astype(np.uint8)  # Convert to uint8\n",
    "\n",
    "#indices = np.fromfile('indices_4d_256k_rayleigh_img22.bin', dtype=np.uint8)\n",
    "\n",
    "\n",
    "# Initialize RS codec\n",
    "r = 127  # Redundancy (4 symbols per block)\n",
    "n = 255  # Total symbols per block  , Do not change this\n",
    "data_symbols = n - r  # Data symbols per block\n",
    "rs = reedsolo.RSCodec(r)\n",
    "\n",
    "# Transmitter\n",
    "def encode_blocks(indices, output_file):\n",
    "    # Calculate padding\n",
    "    padding_length = (data_symbols - (len(indices) % data_symbols)) % data_symbols  # Padding to align data size to block size\n",
    "    padded_indices = np.pad(indices, (0, padding_length), mode='constant', constant_values=0)\n",
    "    indices_bytes = padded_indices.tobytes()\n",
    "\n",
    "    # Ensure that padded data length aligns with expected block size\n",
    "    assert len(indices_bytes) % data_symbols == 0, \"Padded data size is not aligned with the block size.\"\n",
    "\n",
    "    # Encode the data\n",
    "    encoded_data = rs.encode(indices_bytes)\n",
    "\n",
    "    # Save encoded data to a .bin file\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(encoded_data)\n",
    "\n",
    "    print(f\"Encoded data saved to {output_file}\")\n",
    "    return len(indices), len(padded_indices), encoded_data\n",
    "\n",
    "k = 256\n",
    "chunk_size = 4\n",
    "img_no = '22'\n",
    "# Transmit the encoded data\n",
    "original_size, padded_size, encoded_data = encode_blocks(indices_np, f\"indices_ec_{chunk_size}d_{k}k_img{img_no}.bin\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulating noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing 6854 errors out of 195840 total bits (ratio = 0.035).\n",
      "Noisy data saved to received_indices_ec_4d_256k_img22.bin\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_noise_to_bin_file(input_file, output_file, error_ratio):\n",
    "    \"\"\"\n",
    "    Adds noise to an encoded .bin file by flipping a fraction of bits.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the input encoded .bin file.\n",
    "        output_file (str): Path to save the noisy .bin file.\n",
    "        error_ratio (float): Fraction of bits to flip (e.g., 0.01 for 1% of bits).\n",
    "    \"\"\"\n",
    "    # Read the encoded data from the input file\n",
    "    with open(input_file, \"rb\") as f:\n",
    "        encoded_data = bytearray(f.read())\n",
    "\n",
    "    # Calculate total number of bits and the number of errors to introduce\n",
    "    total_bits = len(encoded_data) * 8\n",
    "    num_errors = int(total_bits * error_ratio)\n",
    "    print(f\"Introducing {num_errors} errors out of {total_bits} total bits (ratio = {error_ratio}).\")\n",
    "\n",
    "    # Add noise by flipping random bits\n",
    "    for _ in range(num_errors):\n",
    "        byte_index = np.random.randint(len(encoded_data))  # Choose a random byte\n",
    "        bit_index = np.random.randint(8)  # Choose a random bit within that byte\n",
    "        encoded_data[byte_index] ^= (1 << bit_index)  # Flip the chosen bit\n",
    "\n",
    "    # Save the noisy data to the output file\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(encoded_data)\n",
    "\n",
    "    print(f\"Noisy data saved to {output_file}\")\n",
    "\n",
    "# Example Usage\n",
    "input_file = f\"indices_ec_{chunk_size}d_{k}k_img{img_no}.bin\" # Path to the encoded .bin file\n",
    "output_file = f\"received_indices_ec_{chunk_size}d_{k}k_img{img_no}.bin\"   # Path to save the noisy .bin file\n",
    "error_ratio = 0.035               # Introduce 1% bit errors\n",
    "\n",
    "add_noise_to_bin_file(input_file, output_file, error_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12288, 12328, 23460)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_size, padded_size, len(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Receiver for Swin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding 96 blocks of size 255 bytes each.\n",
      "Block 5 could not be decoded. Retaining noisy data.\n",
      "Block 8 could not be decoded. Retaining noisy data.\n",
      "Block 11 could not be decoded. Retaining noisy data.\n",
      "Block 12 could not be decoded. Retaining noisy data.\n",
      "Block 13 could not be decoded. Retaining noisy data.\n",
      "Block 14 could not be decoded. Retaining noisy data.\n",
      "Block 17 could not be decoded. Retaining noisy data.\n",
      "Block 19 could not be decoded. Retaining noisy data.\n",
      "Block 20 could not be decoded. Retaining noisy data.\n",
      "Block 29 could not be decoded. Retaining noisy data.\n",
      "Block 30 could not be decoded. Retaining noisy data.\n",
      "Block 32 could not be decoded. Retaining noisy data.\n",
      "Block 34 could not be decoded. Retaining noisy data.\n",
      "Block 36 could not be decoded. Retaining noisy data.\n",
      "Block 42 could not be decoded. Retaining noisy data.\n",
      "Block 49 could not be decoded. Retaining noisy data.\n",
      "Block 55 could not be decoded. Retaining noisy data.\n",
      "Block 57 could not be decoded. Retaining noisy data.\n",
      "Block 61 could not be decoded. Retaining noisy data.\n",
      "Block 63 could not be decoded. Retaining noisy data.\n",
      "Block 67 could not be decoded. Retaining noisy data.\n",
      "Block 71 could not be decoded. Retaining noisy data.\n",
      "Block 74 could not be decoded. Retaining noisy data.\n",
      "Block 80 could not be decoded. Retaining noisy data.\n",
      "Block 82 could not be decoded. Retaining noisy data.\n",
      "Block 85 could not be decoded. Retaining noisy data.\n",
      "Block 90 could not be decoded. Retaining noisy data.\n",
      "Block 91 could not be decoded. Retaining noisy data.\n",
      "Recovered indices saved to recovered_indices_4d_256k_img22.bin.\n",
      "Recovered Indices Tensor:\n",
      "tensor([240, 197,  79,  ...,  35,  60, 105], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import reedsolo\n",
    "\n",
    "# Initialize RS codec\n",
    "r = 127  # Redundancy (4 symbols per block)\n",
    "n = 255  # Total symbols per block, do not change this\n",
    "data_symbols = n - r  # Data symbols per block\n",
    "rs = reedsolo.RSCodec(r)\n",
    "\n",
    "# Original size of the data before encoding\n",
    "original_size = 12288  # Know original size  (32 x H x W / (16 x 16 x 4))  4 because of 4d codebook\n",
    "\n",
    "k = 256\n",
    "chunk_size = 4\n",
    "img_no = '22'\n",
    "\n",
    "resolution = (512,768)\n",
    "original_size = 32 * resolution[0] * resolution[1] // (16 * 16 * chunk_size)  # Know original size  (32 x H x W / (16 x 16 x 4))  4 because of 4d codebook\n",
    "\n",
    "\n",
    "# Function to process and decode blocks from a .bin file\n",
    "def decode_blocks(input_file, block_size, data_size, redundancy, original_size):\n",
    "    \"\"\"\n",
    "    Decodes a .bin file containing noisy encoded data block by block.\n",
    "    \"\"\"\n",
    "    decoded_result = bytearray()\n",
    "\n",
    "    # Load the noisy encoded data from the file\n",
    "    with open(input_file, \"rb\") as f:\n",
    "        encoded_data = f.read()\n",
    "\n",
    "    # Calculate number of blocks\n",
    "    num_blocks = len(encoded_data) // block_size\n",
    "    print(f\"Decoding {num_blocks} blocks of size {block_size} bytes each.\")\n",
    "\n",
    "    for i in range(num_blocks):\n",
    "        start = i * block_size\n",
    "        end = start + block_size\n",
    "        block = encoded_data[start:end]\n",
    "\n",
    "        try:\n",
    "            # Attempt to decode the block\n",
    "            decoded_block = rs.decode(block)\n",
    "            if isinstance(decoded_block, tuple):  # Handle tuple output\n",
    "                decoded_block = decoded_block[0]\n",
    "            decoded_result.extend(decoded_block[:data_size])  # Append only data symbols\n",
    "        except reedsolo.ReedSolomonError:\n",
    "            # Decoding failed, append raw noisy data for this block\n",
    "            print(f\"Block {i + 1} could not be decoded. Retaining noisy data.\")\n",
    "            decoded_result.extend(block[:data_size])  # Append raw data symbols (exclude redundancy)\n",
    "\n",
    "    # Trim decoded result to match the original size\n",
    "    return decoded_result[:original_size]\n",
    "\n",
    "# Path to the noisy .bin file at the receiver\n",
    "input_file = f\"received_indices_ec_{chunk_size}d_{k}k_img{img_no}.bin\"\n",
    "output_indices_file = f\"recovered_indices_{chunk_size}d_{k}k_img{img_no}.bin\"\n",
    "\n",
    "# Decode the noisy data from the .bin file\n",
    "decoded_data = decode_blocks(input_file, block_size=n, data_size=data_symbols, redundancy=r, original_size=original_size)\n",
    "\n",
    "# Convert the decoded bytearray to indices\n",
    "decoded_indices = np.frombuffer(decoded_data, dtype=np.uint8)\n",
    "\n",
    "# Save recovered indices to a binary file\n",
    "with open(output_indices_file, \"wb\") as f:\n",
    "    f.write(decoded_indices.tobytes())\n",
    "\n",
    "print(f\"Recovered indices saved to {output_indices_file}.\")\n",
    "\n",
    "recovered_indices = torch.from_numpy(decoded_indices).int()  # Convert to int32\n",
    "print(\"Recovered Indices Tensor:\")\n",
    "print(recovered_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([240, 197,  79, ...,  35,  60, 105], dtype=uint8)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity: 92.02%\n",
      "Errors: 980 out of 12288 elements\n"
     ]
    }
   ],
   "source": [
    "# calculate number of similar elements between indices and decoded indices and give percentage\n",
    "\n",
    "def calculate_similarity(indices, decoded_indices):\n",
    "    num_similar = np.sum(indices == decoded_indices)\n",
    "    total_elements = indices.size\n",
    "    similarity = num_similar / total_elements\n",
    "    return similarity, num_similar, total_elements\n",
    "\n",
    "similarity,num_similar, total_elements = calculate_similarity(indices_np, decoded_indices)\n",
    "print(f\"\\nSimilarity: {similarity:.2%}\")\n",
    "print(f\"Errors: {total_elements - num_similar} out of {total_elements} elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing 2499 errors out of 99960 total bits (ratio = 0.025).\n",
      "Noisy data saved to noisy_data.bin\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_noise_to_bin_file(input_file, output_file, error_ratio):\n",
    "    \"\"\"\n",
    "    Adds noise to an encoded .bin file by flipping a fraction of bits.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the input encoded .bin file.\n",
    "        output_file (str): Path to save the noisy .bin file.\n",
    "        error_ratio (float): Fraction of bits to flip (e.g., 0.01 for 1% of bits).\n",
    "    \"\"\"\n",
    "    # Read the encoded data from the input file\n",
    "    with open(input_file, \"rb\") as f:\n",
    "        encoded_data = bytearray(f.read())\n",
    "\n",
    "    # Calculate total number of bits and the number of errors to introduce\n",
    "    total_bits = len(encoded_data) * 8\n",
    "    num_errors = int(total_bits * error_ratio)\n",
    "    print(f\"Introducing {num_errors} errors out of {total_bits} total bits (ratio = {error_ratio}).\")\n",
    "\n",
    "    # Add noise by flipping random bits\n",
    "    for _ in range(num_errors):\n",
    "        byte_index = np.random.randint(len(encoded_data))  # Choose a random byte\n",
    "        bit_index = np.random.randint(8)  # Choose a random bit within that byte\n",
    "        encoded_data[byte_index] ^= (1 << bit_index)  # Flip the chosen bit\n",
    "\n",
    "    # Save the noisy data to the output file\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(encoded_data)\n",
    "\n",
    "    print(f\"Noisy data saved to {output_file}\")\n",
    "\n",
    "# Example Usage\n",
    "input_file = \"transmitted_data_4d_256k.bin\"  # Path to the encoded .bin file\n",
    "output_file = \"noisy_data.bin\"   # Path to save the noisy .bin file\n",
    "error_ratio = 0.025               # Introduce 1% bit errors\n",
    "\n",
    "add_noise_to_bin_file(input_file, output_file, error_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data saved to transmitted_data.bin\n",
      "Encoded data saved to transmitted_data.bin\n",
      "Introducing 6936 errors out of 173400 total bits (ratio = 0.04).\n",
      "Noisy data saved to noisy_data.bin\n",
      "Decoding 85 blocks of size 255 bytes each.\n",
      "Block 1 could not be decoded. Retaining noisy data.\n",
      "Block 2 could not be decoded. Retaining noisy data.\n",
      "Block 3 could not be decoded. Retaining noisy data.\n",
      "Block 4 could not be decoded. Retaining noisy data.\n",
      "Block 5 could not be decoded. Retaining noisy data.\n",
      "Block 6 could not be decoded. Retaining noisy data.\n",
      "Block 7 could not be decoded. Retaining noisy data.\n",
      "Block 8 could not be decoded. Retaining noisy data.\n",
      "Block 9 could not be decoded. Retaining noisy data.\n",
      "Block 10 could not be decoded. Retaining noisy data.\n",
      "Block 11 could not be decoded. Retaining noisy data.\n",
      "Block 12 could not be decoded. Retaining noisy data.\n",
      "Block 13 could not be decoded. Retaining noisy data.\n",
      "Block 14 could not be decoded. Retaining noisy data.\n",
      "Block 15 could not be decoded. Retaining noisy data.\n",
      "Block 16 could not be decoded. Retaining noisy data.\n",
      "Block 17 could not be decoded. Retaining noisy data.\n",
      "Block 18 could not be decoded. Retaining noisy data.\n",
      "Block 19 could not be decoded. Retaining noisy data.\n",
      "Block 20 could not be decoded. Retaining noisy data.\n",
      "Block 21 could not be decoded. Retaining noisy data.\n",
      "Block 22 could not be decoded. Retaining noisy data.\n",
      "Block 23 could not be decoded. Retaining noisy data.\n",
      "Block 24 could not be decoded. Retaining noisy data.\n",
      "Block 25 could not be decoded. Retaining noisy data.\n",
      "Block 26 could not be decoded. Retaining noisy data.\n",
      "Block 27 could not be decoded. Retaining noisy data.\n",
      "Block 28 could not be decoded. Retaining noisy data.\n",
      "Block 29 could not be decoded. Retaining noisy data.\n",
      "Block 30 could not be decoded. Retaining noisy data.\n",
      "Block 31 could not be decoded. Retaining noisy data.\n",
      "Block 32 could not be decoded. Retaining noisy data.\n",
      "Block 33 could not be decoded. Retaining noisy data.\n",
      "Block 34 could not be decoded. Retaining noisy data.\n",
      "Block 35 could not be decoded. Retaining noisy data.\n",
      "Block 36 could not be decoded. Retaining noisy data.\n",
      "Block 37 could not be decoded. Retaining noisy data.\n",
      "Block 38 could not be decoded. Retaining noisy data.\n",
      "Block 39 could not be decoded. Retaining noisy data.\n",
      "Block 40 could not be decoded. Retaining noisy data.\n",
      "Block 41 could not be decoded. Retaining noisy data.\n",
      "Block 42 could not be decoded. Retaining noisy data.\n",
      "Block 43 could not be decoded. Retaining noisy data.\n",
      "Block 44 could not be decoded. Retaining noisy data.\n",
      "Block 45 could not be decoded. Retaining noisy data.\n",
      "Block 46 could not be decoded. Retaining noisy data.\n",
      "Block 47 could not be decoded. Retaining noisy data.\n",
      "Block 48 could not be decoded. Retaining noisy data.\n",
      "Block 49 could not be decoded. Retaining noisy data.\n",
      "Block 50 could not be decoded. Retaining noisy data.\n",
      "Block 51 could not be decoded. Retaining noisy data.\n",
      "Block 52 could not be decoded. Retaining noisy data.\n",
      "Block 53 could not be decoded. Retaining noisy data.\n",
      "Block 54 could not be decoded. Retaining noisy data.\n",
      "Block 55 could not be decoded. Retaining noisy data.\n",
      "Block 56 could not be decoded. Retaining noisy data.\n",
      "Block 57 could not be decoded. Retaining noisy data.\n",
      "Block 58 could not be decoded. Retaining noisy data.\n",
      "Block 59 could not be decoded. Retaining noisy data.\n",
      "Block 60 could not be decoded. Retaining noisy data.\n",
      "Block 61 could not be decoded. Retaining noisy data.\n",
      "Block 62 could not be decoded. Retaining noisy data.\n",
      "Block 63 could not be decoded. Retaining noisy data.\n",
      "Block 64 could not be decoded. Retaining noisy data.\n",
      "Block 65 could not be decoded. Retaining noisy data.\n",
      "Block 66 could not be decoded. Retaining noisy data.\n",
      "Block 67 could not be decoded. Retaining noisy data.\n",
      "Block 68 could not be decoded. Retaining noisy data.\n",
      "Block 69 could not be decoded. Retaining noisy data.\n",
      "Block 70 could not be decoded. Retaining noisy data.\n",
      "Block 72 could not be decoded. Retaining noisy data.\n",
      "Block 74 could not be decoded. Retaining noisy data.\n",
      "Block 75 could not be decoded. Retaining noisy data.\n",
      "Block 76 could not be decoded. Retaining noisy data.\n",
      "Block 77 could not be decoded. Retaining noisy data.\n",
      "Block 78 could not be decoded. Retaining noisy data.\n",
      "Block 79 could not be decoded. Retaining noisy data.\n",
      "Block 80 could not be decoded. Retaining noisy data.\n",
      "Block 82 could not be decoded. Retaining noisy data.\n",
      "Block 83 could not be decoded. Retaining noisy data.\n",
      "Block 84 could not be decoded. Retaining noisy data.\n",
      "Block 85 could not be decoded. Retaining noisy data.\n",
      "Decoded indices saved to decoded_indices.bin\n",
      "\n",
      "Decoded Indices (Best Effort):\n",
      "[ 41  94 219 ... 207  74 245]\n",
      "\n",
      "Original Indices:\n",
      "[ 41  94 218 ... 207  72 245]\n",
      "\n",
      "Original shape: (12288,), Decoded shape: (12288,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import reedsolo\n",
    "\n",
    "# Initialize RS codec\n",
    "r = 110  # Redundancy (4 symbols per block)\n",
    "n = 255  # Total symbols per block\n",
    "k = n - r  # Data symbols per block\n",
    "rs = reedsolo.RSCodec(r)\n",
    "\n",
    "def transmitter(indices, output_file):\n",
    "    # Calculate padding\n",
    "    padding_length = (k - (len(indices) % k)) % k  # Padding to align data size to block size\n",
    "    padded_indices = np.pad(indices, (0, padding_length), mode='constant', constant_values=0)\n",
    "    indices_bytes = padded_indices.tobytes()\n",
    "\n",
    "    # Ensure that padded data length aligns with expected block size\n",
    "    assert len(indices_bytes) % k == 0, \"Padded data size is not aligned with the block size.\"\n",
    "\n",
    "    # Encode the data\n",
    "    encoded_data = rs.encode(indices_bytes)\n",
    "\n",
    "    # Save encoded data to a .bin file\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(encoded_data)\n",
    "\n",
    "    print(f\"Encoded data saved to {output_file}\")\n",
    "    return len(indices), len(padded_indices), encoded_data\n",
    "\n",
    "# Generate simulated data\n",
    "original_size = 12288  # Original data size (indices count)\n",
    "indices = np.random.randint(0, 256, size=(original_size,), dtype=np.uint8)  # uint8 indices\n",
    "\n",
    "# Transmit the encoded data\n",
    "original_size, padded_size, encoded_data = transmitter(indices, \"transmitted_data.bin\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_noise(input_file, output_file, error_ratio):\n",
    "    \"\"\"\n",
    "    Add noise to the data in a binary file based on a given error ratio.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the input binary file.\n",
    "        output_file (str): Path to save the noisy binary file.\n",
    "        error_ratio (float): Fraction of bits to flip (e.g., 0.01 for 1% of bits).\n",
    "    \n",
    "    Returns:\n",
    "        noisy_data (bytes): The noisy data.\n",
    "    \"\"\"\n",
    "    # Read encoded data from file\n",
    "    with open(input_file, \"rb\") as f:\n",
    "        encoded_data = f.read()\n",
    "\n",
    "    # Calculate the total number of bits in the file\n",
    "    total_bits = len(encoded_data) * 8\n",
    "\n",
    "    # Calculate the number of errors based on the error ratio\n",
    "    num_errors = int(total_bits * error_ratio)\n",
    "    print(f\"Introducing {num_errors} errors out of {total_bits} total bits (ratio = {error_ratio}).\")\n",
    "\n",
    "    # Add noise to the data\n",
    "    noisy_data = bytearray(encoded_data)\n",
    "    for _ in range(num_errors):\n",
    "        byte_index = np.random.randint(len(noisy_data))\n",
    "        bit_index = np.random.randint(8)\n",
    "        noisy_data[byte_index] ^= (1 << bit_index)  # Flip a random bit\n",
    "\n",
    "    # Save the noisy data to a .bin file\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(noisy_data)\n",
    "\n",
    "    print(f\"Noisy data saved to {output_file}\")\n",
    "    return noisy_data\n",
    "\n",
    "\n",
    "\n",
    "def receiver(input_file, output_file, original_size):\n",
    "    # Load noisy data\n",
    "    with open(input_file, \"rb\") as f:\n",
    "        received_data = f.read()\n",
    "\n",
    "    # Decode block by block\n",
    "    def decode_blocks(encoded_data, block_size, data_size, redundancy):\n",
    "        decoded_result = bytearray()\n",
    "        num_blocks = len(encoded_data) // block_size\n",
    "\n",
    "        print(f\"Decoding {num_blocks} blocks of size {block_size} bytes each.\")\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            start = i * block_size\n",
    "            end = start + block_size\n",
    "            block = encoded_data[start:end]\n",
    "\n",
    "            try:\n",
    "                # Attempt to decode the block\n",
    "                decoded_block = rs.decode(block)\n",
    "                if isinstance(decoded_block, tuple):  # Handle tuple output\n",
    "                    decoded_block = decoded_block[0]\n",
    "                decoded_result.extend(decoded_block[:data_size])  # Append only data symbols\n",
    "            except reedsolo.ReedSolomonError:\n",
    "                # Decoding failed, append raw noisy data for this block\n",
    "                print(f\"Block {i + 1} could not be decoded. Retaining noisy data.\")\n",
    "                decoded_result.extend(block[:data_size])  # Append raw data symbols (exclude redundancy)\n",
    "\n",
    "        return decoded_result\n",
    "\n",
    "    # Decode the noisy data\n",
    "    decoded_data = decode_blocks(received_data, block_size=n, data_size=k, redundancy=r)\n",
    "\n",
    "    # Remove padding\n",
    "    decoded_data = decoded_data[:original_size]  # Trim to original data size (bytes)\n",
    "    decoded_indices = np.frombuffer(decoded_data, dtype=np.uint8)\n",
    "\n",
    "    # Save decoded indices to a .bin file\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(decoded_indices.tobytes())\n",
    "\n",
    "    print(f\"Decoded indices saved to {output_file}\")\n",
    "    return decoded_indices\n",
    "\n",
    "# Transmit the data\n",
    "original_size, padded_size, encoded_data = transmitter(indices, \"transmitted_data.bin\")\n",
    "\n",
    "# Simulate noise\n",
    "#noisy_data = add_noise(\"transmitted_data.bin\", \"noisy_data.bin\", num_errors=30)\n",
    "noisy_data = add_noise(\"transmitted_data.bin\", \"noisy_data.bin\", error_ratio= 0.04)\n",
    "\n",
    "\n",
    "# Receive and decode the data\n",
    "decoded_indices = receiver(\"noisy_data.bin\", \"decoded_indices.bin\", original_size)\n",
    "\n",
    "# Validate shapes\n",
    "print(\"\\nDecoded Indices (Best Effort):\")\n",
    "print(decoded_indices)\n",
    "\n",
    "print(\"\\nOriginal Indices:\")\n",
    "print(indices)\n",
    "\n",
    "print(f\"\\nOriginal shape: {indices.shape}, Decoded shape: {decoded_indices.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity: 74.03%\n",
      "Errors: 3191 out of 12288 elements\n"
     ]
    }
   ],
   "source": [
    "# calculate number of similar elements between indices and decoded indices and give percentage\n",
    "\n",
    "def calculate_similarity(indices, decoded_indices):\n",
    "    num_similar = np.sum(indices == decoded_indices)\n",
    "    total_elements = indices.size\n",
    "    similarity = num_similar / total_elements\n",
    "    return similarity, num_similar, total_elements\n",
    "\n",
    "similarity,num_similar, total_elements = calculate_similarity(indices, decoded_indices)\n",
    "print(f\"\\nSimilarity: {similarity:.2%}\")\n",
    "print(f\"Errors: {total_elements - num_similar} out of {total_elements} elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bit Error Rate: 3.85e-02\n",
      "Number of bit errors: 6678\n",
      "Total number of bits: 173400\n"
     ]
    }
   ],
   "source": [
    "def calculate_ber(bin_file1, bin_file2):\n",
    "    with open(bin_file1, 'rb') as file1, open(bin_file2, 'rb') as file2:\n",
    "        data1 = file1.read()\n",
    "        data2 = file2.read()\n",
    "    \n",
    "    # Calculate the number of bit errors\n",
    "    bit_errors = sum(bin(int(byte1) ^ int(byte2)).count('1') for byte1, byte2 in zip(data1, data2))\n",
    "    \n",
    "    # Calculate the bit error rate\n",
    "    ber = bit_errors / (8 * len(data1))\n",
    "    return ber, bit_errors, len(data1)*8\n",
    "\n",
    "ber, errors, bits = calculate_ber('transmitted_data.bin', 'noisy_data.bin')\n",
    "print(f\"Bit Error Rate: {ber:.2e}\")\n",
    "print(f\"Number of bit errors: {errors}\")\n",
    "print(f\"Total number of bits: {bits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ber, errors, bits = calculate_ber('encoded_feature_rayleigh_image24.bin', 'corrupted_feature_rayleigh_image24.bin')\n",
    "print(f\"Bit Error Rate: {ber:.2e}\")\n",
    "print(f\"Number of bit errors: {errors}\")\n",
    "print(f\"Total number of bits: {bits}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
